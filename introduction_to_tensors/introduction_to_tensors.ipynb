{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terragon.de PyTorch Tutorial (German)\n",
    "## Was ist ein Tensor?\n",
    "## Video 1: https://www.youtube.com/watch?v=a8U0M96H--8\n",
    "## Video 2: https://www.youtube.com/watch?v=V7br4vChTJY\n",
    "## Video 3: https://www.youtube.com/watch?v=rrZjDVfte9Y\n",
    "\n",
    "In diesem Tutorial sehen wir was ein Tensor ist und was wir mit ihm machen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensoren sind mehrdimensionale Arrays\n",
    "\n",
    "Alle Tensoren sind demzufolge N-dimensionale Arrays.\n",
    "\n",
    "Die Bezeichnngen unterscheiden sich üblicherweise:\n",
    "\n",
    "- für nulldimensionale Tensoren als Nummer oder Skalar (Rank 0)\n",
    "- für eindimensionale Tensoren als Array oder Vektor (Rank 1)\n",
    "- für zweidimensionale Tensoren als 2-D Array oder Matrix (Rank 2)\n",
    "\n",
    "Die Dimension eines Tensors wird auch als Rank bezeichnet. Rank 2 bedeutet zum Beispiel, dass er zwei Achsen hat.\n",
    "\n",
    "Der Shape eines Tensors gibt die Längen der Achsen an, beziehungsweise wie viele Indexe es pro Achse gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Rank 0 Tensor (Skalar)\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "rank0 = [1]\n",
    "rank0 = torch.tensor(rank0)\n",
    "print(rank0)\n",
    "print(rank0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Rank 1 Tensor (Vektor)\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "rank1 = [1,2,3]\n",
    "rank1 = torch.tensor(rank1)\n",
    "print(rank1)\n",
    "print(rank1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Rank 2 Tensor (Matrix)\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8\n",
    "\n",
    "Beispiel für einen zweidimensionalen Tensor (Rank zwei, mit zwei Achsen).\n",
    "\n",
    "Die 1. Achse wird von links nach rechts und die 2. Achse wird von oben nach unten gelesen.\n",
    "\n",
    "Entlang der ersten Achse (von links nach rechts) ist jedes Element ein Array [1,2,3]...[1,2,3].\n",
    "\n",
    "Entlang der zweiten Achse (von oben nach unten) ist jedes Element eine einzelne Zahl (1,1,1) ... (3,3,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "rank2 = [[1,2,3],[1,2,3],[1,2,3],[1,2,3]]\n",
    "rank2 = torch.tensor(rank2)\n",
    "print(rank2)\n",
    "print(rank2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape und Size\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8\n",
    "\n",
    "Shape und Size des Tensors sind das gleiche. Deshalb ist der Output \"Size\" obwohl man \"Shape\" schreibt.\n",
    "\n",
    "Der Rang eines Tensors ist gleichbedeutend mit der Länge des Shape.\n",
    "\n",
    "In dem Beispiel ist der Shape des Tensors gleichbedeutend mit\n",
    "- Achse eins mit vier Elementen\n",
    "- Achse zwei mit drei Elementen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (Size) des Rank 2 Tensors: \n",
      "torch.Size([4, 3])\n",
      "Rang des Rank 2 Tensors (Länge des Shape): \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape (Size) des Rank 2 Tensors: \")\n",
    "print(rank2.shape)\n",
    "\n",
    "print(\"Rang des Rank 2 Tensors (Länge des Shape): \")\n",
    "print(len(rank2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute von Tensoren\n",
    "\n",
    "Jetzt können wir die verschiedenen Attribute für den Tensor anzeigen.\n",
    "\n",
    "Wenn Tensoren zusammenarbeiten sollen, müssen sie denselben Datentyp haben und auf demselben Device liegen.\n",
    "\n",
    "Beim Erstellen des PyTorch Tensors wird der Datentyp automatisch aus den Eingabewerten ermittelt.\n",
    "- Wenn alles nur glatte Zahlen sind, nimmt er das Format int64\n",
    "- wenn es Kommazahlen sind, nutzt er automatisch float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Attribute des Rank 2 Tensors: \n",
      "torch.int64\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Attribute des Rank 2 Tensors: \")\n",
    "print(rank2.dtype)  # Datentyp im Tensor\n",
    "print(rank2.device) # CPU oder GPU\n",
    "print(rank2.layout) # Ablage im Speicher, braucht nicht weiter beachtet werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape\n",
    "\n",
    "Video 2: https://www.youtube.com/watch?v=V7br4vChTJY\n",
    "\n",
    "Wichtig in neuronalen Netzen ist das sogenannte reshaping.\n",
    "\n",
    "Dabei wird die Länge der Achsen des Tensors verändert, wobei die Anzahl der Elemente gleich bleibt. Beim reshaping muss also die \"Summe\" der neuen Länge der Achsen dieselbe sein wie vorher, da die gleiche Anzahl der Elemente verteilt werden muss. Also 3 x 4 ist das gleiche wie 4 × 3 in dem Beispiel.\n",
    "\n",
    "In dem Beispiel vertauschen wir nur die Anzahl der Zeilen und Spalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des Rank 2 Tensors nach dem reshaping: \n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "rank2 = rank2.reshape(4,3)\n",
    "print(\"Shape des Rank 2 Tensors nach dem reshaping: \")\n",
    "print(rank2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzahl aller Elemente\n",
    "\n",
    "Um zu prüfen, ob die Anzahl der Elemente in dem Tensor immer gleich bleibt, kann man das Produkt der Achsen bzw. des Shape anzeigen.\n",
    "\n",
    "Die Anzahl der Elemente kann auch pro Dimension angezeigt werden (dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produkt der Achsen bzw. Anzahl der Elemente prod(): \n",
      "tensor(12)\n",
      "Alternative mit numel(): \n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(\"Produkt der Achsen bzw. Anzahl der Elemente prod(): \")\n",
    "print(torch.tensor(rank2.shape).prod())\n",
    "print(\"Alternative mit numel(): \")\n",
    "print(rank2.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verknüpfen von Tensoren\n",
    "\n",
    "Um mehrere Tensoren zu verknüpfen gibt es in PyTorch den cat Befehl.\n",
    "\n",
    "Bevor Tensoren verknüpft werden können, müssen sie meistens vorher einen reshape erfahren, da sie auf den selben shape gebracht werden müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "Tensor1 = rank2\n",
    "Tensor2 = rank2\n",
    "\n",
    "Tensor3 = torch.cat((Tensor1, Tensor2), dim=0)\n",
    "\n",
    "print(Tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des verknpften Tensors: \n",
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape des verknpften Tensors: \")\n",
    "print(Tensor3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summe aller Elemente\n",
    "\n",
    "Video 2: https://www.youtube.com/watch?v=V7br4vChTJY\n",
    "\n",
    "Die Summe aller Elemente in einem Tensor wird mit sum() berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Summe aller Elemente in einem Tensor dummy4.sum(): \n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "tensor(24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Summe aller Elemente in einem Tensor dummy4.sum(): \")\n",
    "print(rank2)\n",
    "print(rank2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summe aller Elemente pro Achse\n",
    "\n",
    "Die Summe aller Elemente in einem Tensor, aber nur für eine Dimension (X oder Y Achse).\n",
    "\n",
    "rank2.sum(dim=0)=Spalte und dim=1=Zeile.\n",
    "\n",
    "Ergebnis ist ein Tensor mit mehreren Elementen, weil es die Summe für jede Spalte bzw. Zeile einzeln ausgibt!\n",
    "\n",
    "dim=0 ist Summe von \"oben nach unten\" also Summe pro Spalte\n",
    "dim=1 ist Summe von \"links nach rechts\" also Summe pro Zeile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4,  8, 12])\n",
      "tensor([6, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "print(rank2.sum(dim=0))\n",
    "print(rank2.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produkt und Durchschnitt aller Elemente\n",
    "\n",
    "Video 2: https://www.youtube.com/watch?v=V7br4vChTJY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Produkt aller Elemente in einem Tensor rank2.prod(): \n",
      "tensor(1296)\n",
      "Durchschnitt aller Elemente in einem Tensor rank2.mean(): \n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Das Produkt aller Elemente in einem Tensor rank2.prod(): \")\n",
    "print(rank2.prod())\n",
    "\n",
    "print(\"Durchschnitt aller Elemente in einem Tensor rank2.mean(): \")\n",
    "print(rank2.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
