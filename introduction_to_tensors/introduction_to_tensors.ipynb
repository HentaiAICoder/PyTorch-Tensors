{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terragon.de PyTorch Tutorial (German)\n",
    "## Was ist ein Tensor und was kann ich mit einem Tensor machen?\n",
    "## Video 1: https://www.youtube.com/watch?v=a8U0M96H--8\n",
    "## Video 2: https://www.youtube.com/watch?v=V7br4vChTJY\n",
    "\n",
    "In diesem Tutorial sehen wir was ein Tensor ist und was wir mit ihm machen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensoren sind mehrdimensionale Arrays\n",
    "\n",
    "Alle Tensoren sind demzufolge N-dimensionale Arrays.\n",
    "\n",
    "Die Bezeichnngen unterscheiden sich üblicherweise:\n",
    "\n",
    "- für nulldimensionale Tensoren als Nummer oder Skalar (Rank 0)\n",
    "- für eindimensionale Tensoren als Array oder Vektor (Rank 1)\n",
    "- für zweidimensionale Tensoren als 2-D Array oder Matrix (Rank 2)\n",
    "\n",
    "Die Dimension eines Tensors wird auch als Rank bezeichnet. Rank 2 bedeutet zum Beispiel, dass er zwei Achsen hat.\n",
    "\n",
    "Der Shape eines Tensors gibt die Längen der Achsen an, beziehungsweise wie viele Indexe es pro Achse gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Rank 0 Tensor (Skalar)\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "rank0 = [1]\n",
    "rank0 = torch.tensor(rank0)\n",
    "print(rank0)\n",
    "print(rank0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Rank 1 Tensor (Vektor)\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "rank1 = [1,1,1]\n",
    "rank1 = torch.tensor(rank1)\n",
    "print(rank1)\n",
    "print(rank1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Rank 2 Tensor (Matrix)\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8\n",
    "\n",
    "Beispiel für einen zweidimensionalen Tensor (Rank zwei, mit zwei Achsen).\n",
    "\n",
    "Die 1. Achse wird von links nach rechts und die 2. Achse wird von oben nach unten gelesen.\n",
    "\n",
    "Entlang der ersten Achse (von links nach rechts) ist jedes Element ein Array [1,2,3]...[1,2,3].\n",
    "\n",
    "Entlang der zweiten Achse (von oben nach unten) ist jedes Element eine einzelne Zahl (1,1,1) ... (3,3,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "rank2 = [[1,1,1],[2,2,2],[3,3,3],[4,4,4]]\n",
    "rank2 = torch.tensor(rank2)\n",
    "print(rank2)\n",
    "print(rank2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"20181021 Tensor Tutorial Grafik 1.6 Frage.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape und Size\n",
    "\n",
    "Video 1: https://www.youtube.com/watch?v=a8U0M96H--8\n",
    "\n",
    "Shape und Size des Tensors sind das gleiche. Deshalb ist der Output \"Size\" obwohl man \"Shape\" schreibt.\n",
    "\n",
    "Der Rang eines Tensors ist gleichbedeutend mit der Länge des Shape.\n",
    "\n",
    "In dem Beispiel ist der Shape des Tensors gleichbedeutend mit\n",
    "- Achse eins mit vier Elementen\n",
    "- Achse zwei mit drei Elementen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (Size) des Rank 2 Tensors: \n",
      "torch.Size([4, 3])\n",
      "Rang des Rank 2 Tensors (Länge des Shape): \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape (Size) des Rank 2 Tensors: \")\n",
    "print(rank2.shape)\n",
    "\n",
    "print(\"Rang des Rank 2 Tensors (Länge des Shape): \")\n",
    "print(len(rank2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute von Tensoren\n",
    "\n",
    "Jetzt können wir die verschiedenen Attribute für den Tensor anzeigen.\n",
    "\n",
    "Wenn Tensoren zusammenarbeiten sollen, müssen sie denselben Datentyp haben und auf demselben Device liegen.\n",
    "\n",
    "Beim Erstellen des PyTorch Tensors wird der Datentyp automatisch aus den Eingabewerten ermittelt.\n",
    "- Wenn alles nur glatte Zahlen sind, nimmt er das Format int64\n",
    "- wenn es Kommazahlen sind, nutzt er automatisch float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Attribute des Rank 2 Tensors: \n",
      "torch.int64\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Attribute des Rank 2 Tensors: \")\n",
    "print(rank2.dtype)  # Datentyp im Tensor\n",
    "print(rank2.device) # CPU oder GPU\n",
    "print(rank2.layout) # Ablage im Speicher, braucht nicht weiter beachtet werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape\n",
    "\n",
    "Video 2: https://www.youtube.com/watch?v=V7br4vChTJY\n",
    "\n",
    "Wichtig in neuronalen Netzen ist das sogenannte reshaping.\n",
    "\n",
    "Dabei wird die Länge der Achsen des Tensors verändert, wobei die Anzahl der Elemente gleich bleibt. Beim reshaping muss also die \"Summe\" der neuen Länge der Achsen dieselbe sein wie vorher, da die gleiche Anzahl der Elemente verteilt werden muss. Also 3 x 4 ist das gleiche wie 4 × 3 in dem Beispiel.\n",
    "\n",
    "In dem Beispiel vertauschen wir nur die Anzahl der Zeilen und Spalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des Rank 2 Tensors nach dem reshaping: \n",
      "tensor([[1, 1],\n",
      "        [1, 2],\n",
      "        [2, 2],\n",
      "        [3, 3],\n",
      "        [3, 4],\n",
      "        [4, 4]])\n",
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "rank2 = rank2.reshape(6,2)\n",
    "print(\"Shape des Rank 2 Tensors nach dem reshaping: \")\n",
    "print(rank2)\n",
    "print(rank2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des Rank 2 Tensors nach dem reshaping: \n",
      "tensor([[1, 1, 1, 2, 2, 2],\n",
      "        [3, 3, 3, 4, 4, 4]])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "rank2 = rank2.reshape(2,6)\n",
    "print(\"Shape des Rank 2 Tensors nach dem reshaping: \")\n",
    "print(rank2)\n",
    "print(rank2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank2 = rank2.reshape(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"20181021 Tensor Tutorial Grafik 2.6.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "Wenn man den Rang eines Tensors reduzieren möchte gibt es den Befehl flatten. Dies reduziert alle Achsen auf eine einzige Achse, auf der dann der Reihe nach alle Elemente aufgelistet sind.\n",
    "\n",
    "Bevor ein neuronales Netz einen Tensor in ein fully connected layer übernehmen kann muss man Flatten. Flatten ist also nur ein spezieller Teil des reshape.\n",
    "\n",
    "Zum Beispiel werden bei einem Graustufenbild alle Pixel der Reihe nach i# n einem String mit Flatten aneinandergereiht. Dabei wird von oben links nach unten rechts vorgegangen. Das Ergebnis des Flatten wird dann komplett als Input Layer in das neuronale Netz gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des Tensors vor dem Flatten: \n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape des Tensors vor dem Flatten: \")\n",
    "print(rank2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die -1 wird die Anzahl der Elemente beim Flatten berücksichtigt und alle übrigen Elemente nach der 1. Angabe werden nacheinander aufgereiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des Tensors nach der Flatten-Funktion: \n",
      "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\n",
      "Oder in kurz: \n",
      "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "def flatten(tensor):\n",
    "    tensor = tensor.reshape(1,-1)\n",
    "    tensor = tensor.squeeze()\n",
    "    return tensor\n",
    "\n",
    "print(\"Shape des Tensors nach der Flatten-Funktion: \")\n",
    "print(flatten(rank2))\n",
    "\n",
    "print(\"Oder in kurz: \")\n",
    "print(rank2.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"20181021 Tensor Tutorial Grafik 2.8.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzahl aller Elemente\n",
    "\n",
    "Um zu prüfen, ob die Anzahl der Elemente in dem Tensor immer gleich bleibt, kann man das Produkt der Achsen bzw. des Shape anzeigen.\n",
    "\n",
    "Die Anzahl der Elemente kann auch pro Dimension angezeigt werden (dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produkt der Achsen bzw. Anzahl der Elemente prod(): \n",
      "tensor(12)\n",
      "Alternative mit numel(): \n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(\"Produkt der Achsen bzw. Anzahl der Elemente prod(): \")\n",
    "print(torch.tensor(rank2.shape).prod())\n",
    "print(\"Alternative mit numel(): \")\n",
    "print(rank2.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summe aller Elemente\n",
    "\n",
    "Video 2: https://www.youtube.com/watch?v=V7br4vChTJY\n",
    "\n",
    "Die Summe aller Elemente in einem Tensor wird mit sum() berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Summe aller Elemente in einem Tensor dummy4.sum(): \n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor(30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Summe aller Elemente in einem Tensor dummy4.sum(): \")\n",
    "print(rank2)\n",
    "print(rank2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summe aller Elemente pro Achse\n",
    "\n",
    "Die Summe aller Elemente in einem Tensor, aber nur für eine Dimension (X oder Y Achse).\n",
    "\n",
    "rank2.sum(dim=0)=Spalte und dim=1=Zeile.\n",
    "\n",
    "Ergebnis ist ein Tensor mit mehreren Elementen, weil es die Summe für jede Spalte bzw. Zeile einzeln ausgibt!\n",
    "\n",
    "dim=0 ist Summe von \"oben nach unten\" also Summe pro Spalte\n",
    "dim=1 ist Summe von \"links nach rechts\" also Summe pro Zeile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10])\n",
      "tensor([ 3,  6,  9, 12])\n"
     ]
    }
   ],
   "source": [
    "print(rank2.sum(dim=0))\n",
    "print(rank2.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"20181021 Tensor Tutorial Grafik 2.9.jpg\">\n",
    "<img src=\"20181021 Tensor Tutorial Grafik 2.10.jpg\">\n",
    "<img src=\"20181021 Tensor Tutorial Grafik 2.11.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produkt und Durchschnitt aller Elemente\n",
    "\n",
    "Video 2: https://www.youtube.com/watch?v=V7br4vChTJY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "Das Produkt aller Elemente in einem Tensor rank2.prod(): \n",
      "tensor(13824)\n",
      "Durchschnitt aller Elemente in einem Tensor rank2.mean(): \n",
      "tensor(2.5000)\n",
      "Durchschnitt aller Elemente der Dimension 0 (senkrecht) in einem Tensor rank2.mean(): \n",
      "tensor([2.5000, 2.5000, 2.5000])\n",
      "Durchschnitt aller Elemente der Dimension 1 (waagerecht) in einem Tensor rank2.mean(): \n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "\n",
    "print(\"Das Produkt aller Elemente in einem Tensor rank2.prod(): \")\n",
    "print(rank2.prod())\n",
    "\n",
    "print(\"Durchschnitt aller Elemente in einem Tensor rank2.mean(): \")\n",
    "print(rank2.float().mean())\n",
    "\n",
    "print(\"Durchschnitt aller Elemente der Dimension 0 (senkrecht) in einem Tensor rank2.mean(): \")\n",
    "print(rank2.float().mean(dim=0))\n",
    "\n",
    "print(\"Durchschnitt aller Elemente der Dimension 1 (waagerecht) in einem Tensor rank2.mean(): \")\n",
    "print(rank2.float().mean(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximale Werte max()\n",
    "\n",
    "Die Angabe der maximalen Werte kann entweder auf den gesamten Tensor, oder nur auf eine Dimension (dim=0 oder dim=1) angewendet werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "print(rank2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "torch.return_types.max(\n",
      "values=tensor([4, 4, 4]),\n",
      "indices=tensor([3, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "print(rank2.max(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "torch.return_types.max(\n",
      "values=tensor([1, 2, 3, 4]),\n",
      "indices=tensor([2, 2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "print(rank2.max(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position der maximalen Werte argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor(11)\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "print(rank2.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "print(rank2.argmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(rank2)\n",
    "print(rank2.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"20181021 Tensor Tutorial Grafik 2.13.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
